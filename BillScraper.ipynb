{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d0fe965-1c9b-47de-beb9-56b6cce2cd65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Program Overview\n",
    "<h4>Purpose:</h4> \n",
    "The purpose of this program is to leverage the LegiScan API to automate the collection, identification, and extraction of bill data, minizing manual efforts and improving efficiency.  \n",
    "\n",
    "<br><h4>Requirements:</h4>\n",
    "To run this program you'll need the following\n",
    "- API Key from https://legiscan.com/\n",
    "- Permission to Download & Create new files\n",
    "- Latest Version of Python Installed https://www.python.org/downloads/\n",
    "- Reliable internet\n",
    "\n",
    "<br><h4>Recommendations:</h4>\n",
    "- It is recommended to run the program once per week to check for any updates to bill data\n",
    "- To limit unnecessary API calls when monitoring a small number of states, adjust the *stateCodes* parameter as needed\n",
    "- If the search criteria is too broad or too restrictive, refine or broaden the *relevanceFilter* and *searchTerms* parameters as needed\n",
    "- Do not set relevanceFilter too low, as it'll result in too many subsequent API calls when collecting Bill Info\n",
    "\n",
    "<br><h4>Features:</h4> \n",
    "- Minized API usage by downloading new datasets only when updated are detected\n",
    "- Automatically updating bill data when changes are detected\n",
    "- Adjustable filtering criteria through *relevanceFilter* and *searchTerms* parameters\n",
    "- Aggregation of all collected bill data into a singular dataset for easy exporting and extraction\n",
    "- Exporting all bill data into a single Excel workbook sorted by bill relevance\n",
    "\n",
    "<br><h4>Outputs:</h4> \n",
    "The final codeblock in this program outputs a single Excel workbook with individual sheets that correspond to the dates in the *stateCodes* parameter.\n",
    "Below is a breakdown of each of the columns, please note if a specific cell is empty, it's due to the API not providing an input for that given cell.\n",
    "- *latest_update*: datetime of when the row was aggregated from the dataset, format: *MM-DD-YYYY* \n",
    "- *relevance*: a percentage from (0-100) representing how closely the bill matches the search criteria\n",
    "- *state*: abbreviation of the state the bill is from\n",
    "- *bill_number*: number of the bill\n",
    "- *date_introduced*: date the bill was introduced\n",
    "- *description*: description of the bill\n",
    "- *status*: current status of the bill\n",
    "    - Possible values include: *Introduced*, *Engrossed*, *Enrolled*, *Passed*, *Vetoed*, *Failed*, *N/A*\n",
    "- *link*: direct link to the bill\n",
    "- *chamber*: Legislative chamber associated with the bill\n",
    "    - *Note*: *chamber* is inferred from the prefix of the *bill_number* and may be *House*, *Senate*, or the prefix itself\n",
    "- *party*: political party of the primary sponsor\n",
    "- *primary* sponsor: list of the primary sponsor\n",
    "- *co-sponsor*: list of co-sponsors\n",
    "- *joint sponsor*: list of joint sponsors\n",
    "- *generic/unspecified sponsor*: list of generic/unspecified sponsors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28b04497-cda4-430b-8f7a-d325093f5b51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Config\n",
    "This section will explain the variables in the config, the type of variables, and the formatting necessary for future edits. When making any edits to any existing variables, run the code block to ensure the changes have been saved. Failure to run the code block after making changes will lead to undesired outputs in the final Excel sheet, or the possibility of failing API calls due to an invalid API Key.\n",
    "\n",
    "##### Variables\n",
    "- apiKey [String]\n",
    "    - This is the API Key you received from LegiScan creating an account.\n",
    "    - When entering the key into the config, ensure that it is surrounded by quotation marks.\n",
    "    - EX: apiKey = \"YOUR_API_KEY_HERE\"\n",
    "- relevanceFilter [Integer]\n",
    "    - The relevancy score is a percentage that represents how accurately a bill matches to your search terms.\n",
    "    - By default, the filter percentage is preset to 20, therefore all bills are included. You can change this percentage from 0-100 based off how limited you want your search to be.\n",
    "    - A \"relevance\" column is included in the final Excel Workbook, therefore you can leave this at 0 and use your own judgement to determine a bills relevancy.\n",
    "    - If you do choose to modify *relevanceFilter*, enter it in with no quotation marks. The percentage you choose is the minimum required to be included in the final Excel workbook.\n",
    "    - EX: relevanceFilter = 25 \n",
    "- stateCodes [List]\n",
    "    - These are the abbreviations for all 50 states, plus the Federal Government which is represented as \"DC\".\n",
    "    - By default, all 50 states plus DC have been included. If you want limit your search, simply remove \"[STATE ABBREVIATION]\", from the *stateCodes* variable.\n",
    "    - If you're only looking to select a few states, it's best practice to remove any additional ones you don't need to save on API calls.\n",
    "    - EX: stateCodes = [\"DC\",\"MD\",\"VA\"] --> stateCodes = [\"DC\",\"VA\"]\n",
    "- searchTerms [List]\n",
    "    - These are the search terms/criteria the program will search for across all the bills in the latest session for all of the states in *stateCodes*.\n",
    "    - To broaden your search, simply add a new line and enter in additional search terms following the existing format, and vice versa to limit your search further.\n",
    "    - EX: searchTerms = [\"death penalty\",\"execution method\"] --> searchTerms = [\"death penalty\", \"execution method\", \"capital murder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69225a2b-b270-4f21-980d-220bbad6034f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Abeezar's API Key (30,000/mo limit)\n",
    "apiKey = \"e6cc3653ff0b22a524c6062132a65fd9\"\n",
    "\n",
    "relevanceFilter = 1\n",
    "stateCodes = [\n",
    "    \"US\", \"DC\", \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \n",
    "    \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \n",
    "    \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \n",
    "    \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \n",
    "    \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \n",
    "    \"WI\", \"WY\"\n",
    "]\n",
    "searchTerms = [\n",
    "    \"death penalty\",\n",
    "    \"capital punishment\",\n",
    "    \"capital sexual battery\",\n",
    "    \"execution method\",\n",
    "    \"death sentence\",\n",
    "    \"method of execution\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64742303-deea-47ec-9700-2f5d6c131b93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Initializing Program\n",
    "This section imports any required libraries to run the program itself, as well as create the directories, files, and JSON structures. After running the Config codeblock you must run the codeblock below, otherwise subsequent codeblocks will be unable to run due to un-imported dependencies. This codeblock will also print out any potential errors when creating the directories and files. Should there be any errors, resolve them before moving forward to prevent unnecessary API calls.\n",
    "\n",
    "When a directory or file already exists, you will get the following output. \"*Error: The directory for \"[STATE]\" already exists.*\" This can be ignored, as the files were successful in creation in a prior run of the codeblock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcae7130-1548-4277-bb4d-9ed6a2834439",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import json\n",
    "import datetime\n",
    "import re\n",
    "import openpyxl\n",
    "\n",
    "\n",
    "# Creating stateData folder to store raw and aggregated data\n",
    "try:\n",
    "    os.makedirs(\"stateData\")\n",
    "except PermissionError:\n",
    "    print(\"Permission Denied: Unable to create directory\")\n",
    "except OSError as e:\n",
    "    if e.errno == 17:\n",
    "        print(\"The directory for \\\"stateData\\\" already exists.\")\n",
    "    else:\n",
    "        print(e)\n",
    "except Exception as e:\n",
    "    print(\"[ERROR]: \" + str(e))\n",
    "\n",
    "# Creating folders for each state inside stateData\n",
    "for state in stateCodes:\n",
    "    try:\n",
    "        os.makedirs(\"stateData/\" + state)\n",
    "        os.makedirs(\"stateData/\" + state + \"/data\")\n",
    "        os.makedirs(\"stateData/\" + state + \"/dataset_\" + state)\n",
    "    except PermissionError:\n",
    "        print(\"Permission Denied: Unable to create directory: \")\n",
    "    except OSError as e:\n",
    "        if e.errno == 17:\n",
    "            print(\"The directory for \\\"\" + state + \"\\\" already exists.\")\n",
    "        else:\n",
    "            print(e)\n",
    "    except Exception as e:\n",
    "        print(\"[ERROR]: \" + str(e))\n",
    "\n",
    "    # Checking to see if dataset_info exists, creating if doesn't\n",
    "    if not os.path.exists(\"stateData/\" + state + \"/data/dataset.json\"):\n",
    "        \n",
    "        # JSON Structure for each state's dataset    \n",
    "        data = {\n",
    "            \"date\": \"\",\n",
    "            \"session_id\": \"\",\n",
    "            \"dataset_hash\": \"\",\n",
    "            \"access_key\": \"\"\n",
    "        }\n",
    "        \n",
    "        # Saving JSON structure locally, to edit later\n",
    "        with open(\"stateData/\" + state + \"/data/dataset.json\", \"w\") as file:\n",
    "            json.dump(data, file, indent=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "171ee6e5-2506-4de7-b6e6-81e7eb4d0cef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Downloading Datasets & Locally Storing\n",
    "The codeblock below serves the purpose of finding the dataset for the latest session, checking to see if any updates were made, and downloading the new dataset if updates were made. Run this codeblock on a weekly basis to update your local datasets. Should there be any errors when pulling data from the LegiScan API, an error message with the *status_code* will be outputted to help identify and diagnose the error.\n",
    "\n",
    "Only run this section once per week, if you're doing multiple searchers per week then **DO NOT** run this section, skip over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29e41710-2b96-4c4b-b925-3c15ac0b0bb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Getting dataset locally and extracting into stateData directory for each state\n",
    "for state in stateCodes:\n",
    "    \n",
    "    # LegiScan API call for each state's Datasets\n",
    "    searchURL = \"https://api.legiscan.com/?key=\" + apiKey + \"&op=getDatasetList&state=\" + state\n",
    "    response = requests.get(searchURL)\n",
    "    \n",
    "    # Checking to see if API call was successful\n",
    "    if response.status_code == 200:\n",
    "        latestSession = response.json()[\"datasetlist\"][0]\n",
    "\n",
    "        # Reading State's Dataset Info\n",
    "        with open(\"stateData/\" + state + \"/data/dataset.json\", \"r\") as file:\n",
    "            saved_data = json.load(file)\n",
    "\n",
    "        # Checking to see if Local Dataset Hash matches API's Dataset Hash\n",
    "        # If Local does match API, we skip over downloading a new Dataset\n",
    "        # If Local doesn't match API, we'll download a new Dataset\n",
    "        if str(saved_data[\"dataset_hash\"]) == str(latestSession[\"dataset_hash\"]):\n",
    "            print(\"No update needed for \" + state +  \"'s Dataset. Local dataset_hash matches the API. Only updating \\\"Date\\\" in dataset.json\")\n",
    "            saved_data[\"date\"] = str(datetime.datetime.now())\n",
    "            with open(\"stateData/\" + state + \"/data/dataset.json\", \"w\") as file:\n",
    "                json.dump(saved_data, file, indent=5)\n",
    "\n",
    "            continue\n",
    "        else:\n",
    "            # Local and API dataset hashes don't match, so we'll download a new dataset\n",
    "            \n",
    "            # Updating dataset.json with updated information from API\n",
    "            saved_data[\"date\"] = str(datetime.datetime.now())\n",
    "            saved_data[\"session_id\"] = str(latestSession[\"session_id\"])\n",
    "            saved_data[\"dataset_hash\"] = str(latestSession[\"dataset_hash\"])\n",
    "            saved_data[\"access_key\"] = str(latestSession[\"access_key\"])\n",
    "\n",
    "            # Saving dataset.json file in the stateData directory with updated dataset info\n",
    "            with open(\"stateData/\" + state + \"/data/dataset.json\", \"w\") as file:\n",
    "                json.dump(saved_data, file, indent=5)\n",
    "\n",
    "            # LegiScan API call to download state's dataset\n",
    "            searchURL = searchURL = \"https://api.legiscan.com/?key=\" + apiKey + \"&op=getDatasetRaw&access_key=\" + latestSession[\"access_key\"] + \"&id=\" + str(latestSession[\"session_id\"]) + \"&format=csv\"\n",
    "            response = requests.get(searchURL)\n",
    "            \n",
    "            # Checking to see if API call was successful\n",
    "            if response.status_code == 200:\n",
    "\n",
    "                # Storing dataset in state's folder\n",
    "                with open(\"stateData/\" + state + \"/dataset_Latest.zip\", \"wb\") as file:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        file.write(chunk)\n",
    "                    print(\"Finished Downloading Dataset for: \" + state)\n",
    "                \n",
    "                # Extracting datasets from downloaded Zip file\n",
    "                with zipfile.ZipFile(\"stateData/\" + state +\"/dataset_Latest.zip\" , \"r\") as zipFolder:\n",
    "                    zipFolder.extractall(path=\"stateData/\")\n",
    "\n",
    "                # Finding the name of the dataset folder we extracted \n",
    "                for folder in os.listdir(\"stateData/\" + state):\n",
    "                    if folder != \"dataset_Latest.zip\" and folder != \"data\" and not folder.startswith(\"dataset_\"):\n",
    "                        session_info = folder\n",
    "\n",
    "                # Moving dataset CSV files to dataset_STATE folder\n",
    "                for file in os.listdir(\"stateData/\" + state + \"/\" + session_info + \"/csv\"):\n",
    "                    source = os.path.join(\"stateData/\" + state + \"/\" + session_info + \"/csv\", file)\n",
    "                    destination = os.path.join(\"stateData/\" + state + \"/dataset_\" + state, file)\n",
    "                    try:\n",
    "                        shutil.move(source, destination)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error moving file {file}: {str(e)}\")\n",
    "            else:\n",
    "                print(\"LegiScan API call failed to download dataset.\")\n",
    "                print(\"State: \" + state + \" | Response Code: \" + response.status_code)\n",
    "                continue\n",
    "\n",
    "    else:\n",
    "        print(\"LegiScan API call failed to retrieve State's Dataset list\")\n",
    "        print(\"State: \" + state + \" | Response Code: \" + response.status_code)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c498c06-c9ff-4242-9c8b-891c16b235ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Bill Search\n",
    "The codeblock below will utilize LegiScan's API to search for bills within every state's latest session and store the search results locally to be aggregated later. Should there be any errors when pulling data from the LegiScan API, an error message with the *status_code* will be outputted to help identify and diagnose the error.\n",
    "\n",
    "*Note: This section is very heavy on API calls, please avoid running it more than once per week unless necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "772b462f-20ca-4c10-b61c-8c2b65570156",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# After downloading state's dataset locally, we'll use LegiScan's getSearchRaw to find bills that match our search criteria\n",
    "for state in stateCodes:\n",
    "\n",
    "    # Get the state's current session_id from dataset.json\n",
    "    with open(\"stateData/\" + state + \"/data/dataset.json\", \"r\") as file:\n",
    "        saved_data = json.load(file)\n",
    "        session_id = saved_data[\"session_id\"]\n",
    "    \n",
    "    # Creating searchQuery from search criteria\n",
    "    searchQuery = \"(\" + \"+OR+\".join(f'\"{term}\"' for term in searchTerms) + \")\"\n",
    "    \n",
    "    # LegiScan API call to find matching bills\n",
    "    searchURL = \"https://api.legiscan.com/?key=\" + apiKey + \"&op=getSearchRaw&id=\" + session_id + \"&query=\" + searchQuery\n",
    "    response = requests.get(searchURL)\n",
    "    \n",
    "    # Checking to see if API call was successful\n",
    "    if response.status_code == 200:\n",
    "        # Saving response locally to aggregate data later\n",
    "        with open(\"stateData/\" + state + \"/data/rawSearch.json\", \"w\") as file:\n",
    "            json.dump(response.json(), file, indent=5)\n",
    "    else:\n",
    "        print(\"LegiScan API call failed to retrieve search results for Bills\")\n",
    "        print(\"State: \" + state + \" | Response Code: \" + response.status_code)\n",
    "\n",
    "\n",
    "    # After saving the rawSearch locally, we're going to use the locally saved file to ensure it passes through the relevancyFilter\n",
    "    # if it passes through the relevancy filter we'll save it in bills.json\n",
    "    bills = {}\n",
    "\n",
    "    with open(\"stateData/\" + state + \"/data/rawSearch.json\",\"r\") as file:\n",
    "        rawSearch = json.load(file)\n",
    "\n",
    "    # Skipping over bills if no search results, we want to create bills.json\n",
    "    if \"results\" in rawSearch[\"searchresult\"]: \n",
    "        for bill in rawSearch[\"searchresult\"][\"results\"]:\n",
    "            \n",
    "            # if bill doesn't meet relevance filter, skip over it \n",
    "            if int(bill[\"relevance\"]) < int(relevanceFilter): continue\n",
    "\n",
    "\n",
    "            # use getBill to get raw bill data and save it into bills.json\n",
    "            searchURL = \"https://api.legiscan.com/?key=\" + apiKey + \"&op=getBill&id=\" + str(bill[\"bill_id\"])\n",
    "            response = requests.get(searchURL)\n",
    "\n",
    "            # Checking to see if the API call was successful\n",
    "            if response.status_code == 200:\n",
    "                rawBill = response.json()\n",
    "                bills[bill[\"bill_id\"]] = {\n",
    "                    \"agg\": {\n",
    "                        \"latest_update\": str(datetime.datetime.now().strftime(\"%m-%d-%Y\")),\n",
    "                        \"change_hash\": bill[\"change_hash\"],\n",
    "                        \"relevance\": bill[\"relevance\"]\n",
    "                    },\n",
    "                    \"raw\": rawBill[\"bill\"]\n",
    "                }\n",
    "            else:\n",
    "                print(\"LegiScan API call failed to retrieve bill data.\")\n",
    "                print(\"State: \" + state + \" | Bill ID: \" + bill[\"bill_id\"] + \" |Response Code: \" + response.status_code)\n",
    "            \n",
    "    # Saving all relevant bills locally before aggregating by bill\n",
    "    with open(\"stateData/\" + state + \"/data/bills.json\", \"w\") as file:\n",
    "        json.dump(bills, file, indent=5)\n",
    "        print(state, 'dumping into JSON')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62afd69a-3f8e-4fa1-88ea-49f7379db0b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Parsing & Aggregating Data\n",
    "The codeblock below will parse through the search results from the LegiScan API, and aggregate each dataset into a singular JSON file to later be exported into the Excel Workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05a08138-d9e8-4d14-8b2a-7fe19767725a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dict for bill status'\n",
    "statusDict = {\n",
    "    0: \"N/A\", 1: \"Introduced\", 2: \"Engrossed\",\n",
    "    3: \"Enrolled\", 4: \"Passed\", 5: \"Vetoed\",\n",
    "    6: \"Failed\", 7: \"Override\", 8: \"Chaptered\",\n",
    "    9: \"Refer\", 10: \"Report Pass\", 11: \"Report DNP\",\n",
    "    12: \"Draft\"\n",
    "}\n",
    "\n",
    "# Dict for sponsor types\n",
    "sponsorTypeDict = {\n",
    "    0: \"generic-unspecified\", 1: \"primary\",\n",
    "    2: \"co\", 3: \"joint\"\n",
    "}\n",
    "\n",
    "# Dict for sponsor parties\n",
    "sponsorPartyDict = {\n",
    "    \"1\": \"democrat\", \"2\": \"republican\", \"3\": \"independent\",\n",
    "    \"4\": \"green party\", \"5\": \"libertarian\", \"6\": \"nonpartisan\"\n",
    "}\n",
    "\n",
    "# Parsing through and saving LegiScan getRawSearch pull to find relevant bills plus info to allow for data aggregation by bill\n",
    "for state in stateCodes:\n",
    "\n",
    "    # Reading in State's relevant dataset and aggregating by bill \n",
    "    billsCSV = pd.read_csv(\"stateData/\" + state + \"/dataset_\" + state + \"/bills.csv\", on_bad_lines=\"skip\")\n",
    "    sponsorsCSV = pd.read_csv(\"stateData/\" + state + \"/dataset_\" + state + \"/sponsors.csv\", on_bad_lines=\"skip\")\n",
    "    peopleCSV = pd.read_csv(\"stateData/\" + state + \"/dataset_\" + state + \"/people.csv\", on_bad_lines=\"skip\")\n",
    "    historyCSV = pd.read_csv(\"stateData/\" + state + \"/dataset_\" + state + \"/history.csv\", on_bad_lines=\"skip\")\n",
    "\n",
    "    # Merging together, bills, sponsors, people\n",
    "    merged_df = pd.merge(billsCSV, historyCSV[[\"bill_id\",\"chamber\"]], on=\"bill_id\", how=\"left\")\n",
    "    merged_df = pd.merge(merged_df, sponsorsCSV[[\"bill_id\",\"people_id\",\"position\"]], on=\"bill_id\", how=\"left\")\n",
    "    merged_df = pd.merge(merged_df, peopleCSV[[\"people_id\",\"name\",\"party\"]], on=\"people_id\", how=\"left\")\n",
    "    \n",
    "    # Dropping duplicates and setting index\n",
    "    merged_df.drop_duplicates(inplace=True)\n",
    "    merged_df.set_index(\"bill_id\", inplace=True) \n",
    "\n",
    "    # Read in bills.json to aggregate data by bill\n",
    "    with open(\"stateData/\" + state + \"/data/bills.json\", \"r\") as file:\n",
    "        bills_json = json.load(file)\n",
    "\n",
    "    # Aggregating data by bill\n",
    "    for bill_id in bills_json:\n",
    "        # Error Handling: If some reason we are unable to find the bill locally, skip over it\n",
    "        if billsCSV[billsCSV[\"bill_id\"] == int(bill_id)].empty: continue\n",
    "\n",
    "        # Get the row in billsCSV that matches the bill_id in bills_json\n",
    "        bill_info = billsCSV[billsCSV[\"bill_id\"] == int(bill_id)]\n",
    "\n",
    "        # Populating bills.json \n",
    "        bills_json[bill_id][\"agg\"][\"state\"] = state\n",
    "        bills_json[bill_id][\"agg\"][\"bill number\"] = bill_info[\"bill_number\"].values[0]\n",
    "        bills_json[bill_id][\"agg\"][\"description\"] = bill_info[\"description\"].values[0]\n",
    "        bills_json[bill_id][\"agg\"][\"state link\"] = bill_info[\"state_link\"].values[0]\n",
    "        bills_json[bill_id][\"agg\"][\"legiscan link\"] = bill_info[\"url\"].values[0]\n",
    "\n",
    "        # Error Handling: Some bills have empty progress \n",
    "        if bills_json[bill_id][\"raw\"][\"progress\"]:\n",
    "            bills_json[bill_id][\"agg\"][\"status\"] = {\n",
    "                \"date\": datetime.datetime.strptime(bills_json[bill_id][\"raw\"][\"progress\"][-1][\"date\"], \"%Y-%m-%d\").strftime(\"%m-%d-%Y\"),\n",
    "                \"label\": statusDict.get(bills_json[bill_id][\"raw\"][\"progress\"][-1][\"event\"], \" \"),\n",
    "                \"action\": bill_info[\"last_action\"].values[0]\n",
    "            }\n",
    "            bills_json[bill_id][\"agg\"][\"date introduced\"] = datetime.datetime.strptime(bills_json[bill_id][\"raw\"][\"progress\"][0][\"date\"], \"%Y-%m-%d\").strftime(\"%m-%d-%Y\")\n",
    "        else:\n",
    "            bills_json[bill_id][\"agg\"][\"status\"] = {\n",
    "                \"date\": \" \",\n",
    "                \"label\": \" \",\n",
    "                \"action\": bill_info[\"last_action\"].values[0]\n",
    "            }\n",
    "            bills_json[bill_id][\"agg\"][\"date introduced\"] = \" \"\n",
    "\n",
    "        # Error Handling: Some bills provide party in a Series, some as a String\n",
    "        party = merged_df.loc[int(bill_id)][\"party\"]\n",
    "        if isinstance(party, pd.Series):\n",
    "            bills_json[bill_id][\"agg\"][\"party\"] = merged_df.loc[int(bill_id)][\"party\"].values[0]\n",
    "        else:\n",
    "            bills_json[bill_id][\"agg\"][\"party\"] = merged_df.loc[int(bill_id)][\"party\"]\n",
    "\n",
    "        # Populating chamber, if chamber is not H, A, S, or L, then prefix of bill\n",
    "        if bills_json[bill_id][\"raw\"][\"current_body\"].startswith(\"H\") or bills_json[bill_id][\"raw\"][\"current_body\"].startswith(\"A\"):\n",
    "            bills_json[bill_id][\"agg\"][\"chamber\"] = \"House\"\n",
    "        elif bills_json[bill_id][\"raw\"][\"current_body\"].startswith(\"S\"):\n",
    "            bills_json[bill_id][\"agg\"][\"chamber\"] = \"Senate\"\n",
    "        elif bills_json[bill_id][\"raw\"][\"current_body\"].startswith(\"L\"):\n",
    "            bills_json[bill_id][\"agg\"][\"chamber\"] = \"Legislature\"\n",
    "        else:\n",
    "            # Bills that don't start with H or S will use the prefix of the bill as the chamber\n",
    "            billPrefix = re.match(r\"^[A-Za-z]+\", bill_info[\"bill_number\"].values[0]).group(0)\n",
    "            bills_json[bill_id][\"agg\"][\"chamber\"] = billPrefix\n",
    "\n",
    "        # Creating json structure for sponsors\n",
    "        bills_json[bill_id][\"agg\"][\"sponsors\"] = {\n",
    "            \"type\": {\n",
    "                \"generic-unspecified\": [],\n",
    "                \"primary\": [],\n",
    "                \"co\": [],\n",
    "                \"joint\": []\n",
    "            },\n",
    "            \"sponsor-party\": {\n",
    "                \"democrat\": 0,\n",
    "                \"republican\": 0,\n",
    "                \"independent\": 0,\n",
    "                \"green party\": 0,\n",
    "                \"libertarian\": 0,\n",
    "                \"nonpartisan\": 0\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Populating sponsor names and parties by type\n",
    "        for sponsor in bills_json[bill_id][\"raw\"][\"sponsors\"]:\n",
    "            \n",
    "            # Pulling sponsor type from dict\n",
    "            sponsor_type = sponsorTypeDict.get(sponsor[\"sponsor_type_id\"])\n",
    "            if sponsor_type is not None:\n",
    "                bills_json[bill_id][\"agg\"][\"sponsors\"][\"type\"][sponsor_type].append(sponsor[\"name\"])\n",
    "\n",
    "            # pulling sponsor party from dict\n",
    "            sponsor_party = sponsorPartyDict.get(sponsor[\"party_id\"])\n",
    "            if sponsor_party is not None:\n",
    "                bills_json[bill_id][\"agg\"][\"sponsors\"][\"sponsor-party\"][sponsor_party] += 1\n",
    "\n",
    "        # Aggregating sponsor type into string for each type\n",
    "        for sponsorType in bills_json[bill_id][\"agg\"][\"sponsors\"][\"type\"]:\n",
    "            bills_json[bill_id][\"agg\"][\"sponsors\"][\"type\"][sponsorType] = \", \".join(bills_json[bill_id][\"agg\"][\"sponsors\"][\"type\"][sponsorType])\n",
    "\n",
    "        # Aggregating sponsor parties into string for each type\n",
    "        bills_json[bill_id][\"agg\"][\"sponsors\"][\"sponsor-party\"] = \", \".join(f\"{party_name}: {count}\" for party_name, count in bills_json[bill_id][\"agg\"][\"sponsors\"][\"sponsor-party\"].items() if count > 0)\n",
    "\n",
    "    # Saving Populated bills.json \n",
    "    with open(\"stateData/\" + state + \"/data/bills.json\", \"w\") as file:\n",
    "        json.dump(bills_json, file, indent=5)\n",
    "        \n",
    "print(\"Parsing & Aggregating Datasets Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e5ce759-6f56-49eb-ae6b-24f61dd647be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Exporting Aggregated Data to Excel Workbook\n",
    "The code below will export the aggregated data into a single Excel Workbook which contains individual sheets that represent each state in *stateCodes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3839abc-2745-4f9d-868e-095eee6d30a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install openpyxl\n",
    "# Creating Excel file sheet to populate with bills by state\n",
    "with pd.ExcelWriter(\"US_Legislation_Collected \" + datetime.datetime.now().strftime(\"%m-%d-%Y\") + \".xlsx\") as writer:\n",
    "    for state in stateCodes:\n",
    "        # Reading in aggregated data for state\n",
    "        with open(\"stateData/\" + state + \"/data/bills.json\", \"r\") as file:\n",
    "            bills_json = json.load(file)\n",
    "        # Excel File Column Names\n",
    "        col = [\n",
    "            \"latest_update\",\n",
    "            \"relevance\",\n",
    "            \"state\",\n",
    "            \"bill number\",\n",
    "            \"date introduced\",\n",
    "            \"description\",\n",
    "            \"status date\",\n",
    "            \"status label\",\n",
    "            \"latest action\",\n",
    "            \"state link\", \n",
    "            \"legiscan link\",\n",
    "            \"chamber\", \n",
    "            \"party\",\n",
    "            \"sponsor parties\",\n",
    "            \"primary sponsor\",\n",
    "            \"co-sponsor\",\n",
    "            \"joint sponsor\", \n",
    "            \"generic/unspecified sponsor\",\n",
    "        ]\n",
    "\n",
    "        df = pd.DataFrame(columns=col)\n",
    "        for bill_id in bills_json:\n",
    "            # Skipping over bills that weren't in the dataset\n",
    "            if \"state\" not in bills_json[bill_id][\"agg\"]: continue\n",
    "            \n",
    "            newRow = {\n",
    "                \"latest_update\": bills_json[bill_id][\"agg\"][\"latest_update\"],\n",
    "                \"relevance\": bills_json[bill_id][\"agg\"][\"relevance\"],\n",
    "                \"state\": bills_json[bill_id][\"agg\"][\"state\"],\n",
    "                \"bill number\": bills_json[bill_id][\"agg\"][\"bill number\"],\n",
    "                \"date introduced\": bills_json[bill_id][\"agg\"][\"date introduced\"],\n",
    "                \"description\": bills_json[bill_id][\"agg\"][\"description\"],\n",
    "                \"status date\": bills_json[bill_id][\"agg\"][\"status\"][\"date\"],\n",
    "                \"status label\": bills_json[bill_id][\"agg\"][\"status\"][\"label\"],\n",
    "                \"latest action\": bills_json[bill_id][\"agg\"][\"status\"][\"action\"],\n",
    "                \"state link\": bills_json[bill_id][\"agg\"][\"state link\"],\n",
    "                \"legiscan link\": bills_json[bill_id][\"agg\"][\"legiscan link\"],\n",
    "                \"chamber\": bills_json[bill_id][\"agg\"][\"chamber\"],\n",
    "                \"party\": bills_json[bill_id][\"agg\"][\"party\"],\n",
    "                \"sponsor parties\": bills_json[bill_id][\"agg\"][\"sponsors\"][\"sponsor-party\"],\n",
    "                \"primary sponsor\": bills_json[bill_id][\"agg\"][\"sponsors\"][\"type\"][\"primary\"],\n",
    "                \"co-sponsor\": bills_json[bill_id][\"agg\"][\"sponsors\"][\"type\"][\"co\"],\n",
    "                \"joint sponsor\": bills_json[bill_id][\"agg\"][\"sponsors\"][\"type\"][\"joint\"],\n",
    "                \"generic/unspecified sponsor\": bills_json[bill_id][\"agg\"][\"sponsors\"][\"type\"][\"generic-unspecified\"]\n",
    "                }\n",
    "            df.loc[len(df)] = newRow\n",
    "\n",
    "        df.to_excel(writer, sheet_name=state, index=False)\n",
    "        print(\"Excel Sheet Completed For: \" + state)\n",
    "print(\"Excel Workbook with all states Complete\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BillScraper",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
